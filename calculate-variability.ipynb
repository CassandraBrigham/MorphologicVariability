{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# morph-var 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the morphologic variability of a landform by determining the number and proportion of classes present in a moving window.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine variability space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_sum(numbers, target, partial=[], partial_sum=0):\n",
    "    if partial_sum == target:\n",
    "        yield partial\n",
    "    if partial_sum >= target:\n",
    "        return\n",
    "    for i, n in enumerate(numbers):\n",
    "        remaining = numbers[i + 1:]\n",
    "        yield from subset_sum(remaining, target, partial + [n], partial_sum + n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_list=list(np.linspace(0,1,13))[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_list_1=[]\n",
    "\n",
    "for a in range(0,len(master_list)-1):\n",
    "    master_list_1.append(list(master_list[a]*np.ones(7)))\n",
    "    \n",
    "master_list_1=list(itertools.chain.from_iterable(master_list_1))\n",
    "master_list_1.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df=pd.DataFrame(subset_sum(master_list_1,1)).drop_duplicates().reset_index(drop=True)\n",
    "master_df['count']=master_df.count(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios_df=master_df[master_df['count'] <= 6].iloc[:,0:6].reset_index(drop=True).fillna(0)\n",
    "scenarios_df.loc[-1]=[master_list_1[7],master_list_1[7],master_list_1[7],master_list_1[7],master_list_1[7],master_list_1[7]]\n",
    "scenarios_df.index=scenarios_df.index+1\n",
    "scenarios_df = scenarios_df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_scenarios=len(scenarios_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_classes = pd.DataFrame()\n",
    "std_scenario_prop = pd.DataFrame()\n",
    "diff_prop = pd.DataFrame()\n",
    "for a in range(0,number_scenarios):\n",
    "    scenario_temp = scenarios_df.iloc[a,:]\n",
    "    \n",
    "    number_classes_temp = len(scenario_temp[scenario_temp!=0])\n",
    "    number_classes[a]= pd.Series(number_classes_temp)\n",
    "    \n",
    "    diff_prop_temp=scenario_temp.max()-scenario_temp[scenario_temp!=0].min()\n",
    "    diff_prop[a]=pd.Series(diff_prop_temp)\n",
    "    \n",
    "    std_scenario_prop_temp = np.std(scenario_temp)\n",
    "    std_scenario_prop[a]=pd.Series(std_scenario_prop_temp)\n",
    "\n",
    "std_scenario_prop_norm1=std_scenario_prop.iloc[0,:].max()-std_scenario_prop+number_classes.iloc[0,:]/12\n",
    "std_scenario_prop_norm2=std_scenario_prop_norm1.iloc[0,:]-std_scenario_prop_norm1.iloc[0,:].min()\n",
    "std_scenario_prop_norm3= std_scenario_prop_norm2/std_scenario_prop_norm2.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variability_scenarios = pd.concat([number_classes.iloc[0,:],diff_prop.iloc[0,:],std_scenario_prop_norm3],axis=1)\n",
    "variability_scenarios.columns=['Number of classes','Difference between the highest and lowest non-zero proportions','Variability metric']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variability_scenarios_sorted=variability_scenarios.sort_values(by=['Number of classes','Variability metric'],ascending=[True,True]).drop_duplicates().reset_index(drop=True)\n",
    "variability_scenarios_sorted['Difference between the highest and lowest non-zero proportions'].iat[0]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure()\n",
    "cc=plt.scatter(number_classes,variability_scenarios_sorted['Variability metric'],c=variability_scenarios_sorted['Difference between the highest and lowest non-zero proportions'],cmap='viridis')\n",
    "fig.colorbar(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure()\n",
    "cc=plt.scatter(variability_scenarios_sorted['Variability metric'],variability_scenarios_sorted['Variability metric'],c=number_classes,cmap='viridis')\n",
    "fig.colorbar(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure()\n",
    "cc=plt.scatter(variability_scenarios_sorted.index,variability_scenarios_sorted['Variability metric'],c=variability_scenarios_sorted['Difference between the highest and lowest non-zero proportions'],cmap='viridis')\n",
    "fig.colorbar(cc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate along-strike variability of scarp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_pred = \"../Data2/Classification_results\"\n",
    "file_name =\"KoaeFZ17\"\n",
    "predictions=pd.read_csv(path_pred+\"/\"+file_name+\"_prediction.txt\").iloc[:,1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_distance=\"../Data2/All_distance_filename\"\n",
    "distance=pd.read_csv(path_distance+\"/\"+file_name+\"_distance_filename.txt\").iloc[:,1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_distance=distance.merge(predictions,how='outer',on='filename')\n",
    "predictions=pred_distance['class']\n",
    "distance=pred_distance['distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "half_window_length = 12#\n",
    "window_center = list(pred_distance['class'].index)[half_window_length:len(pred_distance['class'])-half_window_length:1]#int(scarp_height/8)]\n",
    "profile_step=2\n",
    "scarp_length = np.array(window_center)*profile_step\n",
    "position=pd.Series(range((len(pred_distance['class'])*2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_proportions(class_name, series):\n",
    "    find_class_name= series[series.index[series==class_name]]\n",
    "    total_length = len(series.index)\n",
    "    prop_class = len(find_class_name)/total_length\n",
    "    return prop_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variability_scarp = pd.DataFrame(index=range(0,len(window_center)),columns=range(0,4))\n",
    "stdev_prop=[]\n",
    "n_classes=[]\n",
    "\n",
    "for w in range(0,len(window_center)):\n",
    "    \n",
    "    scarp_slice = pd.DataFrame(pred_distance['class'][window_center[w]-half_window_length:window_center[w]+half_window_length], columns=['class'])\n",
    "    length_scarp_slice=len(scarp_slice)\n",
    "    n_classes.append(int(scarp_slice.nunique()))\n",
    "    \n",
    "    \n",
    "    variability_scarp.iloc[w,2]=length_scarp_slice\n",
    "    \n",
    "    class_1_temp = get_class_proportions(1,scarp_slice['class'])\n",
    "    class_2_temp = get_class_proportions(2,scarp_slice['class'])\n",
    "    class_3_temp = get_class_proportions(3,scarp_slice['class'])\n",
    "    class_4_temp = get_class_proportions(4,scarp_slice['class'])\n",
    "    class_5_temp = get_class_proportions(5,scarp_slice['class'])\n",
    "    class_6_temp = get_class_proportions(6,scarp_slice['class'])\n",
    "    \n",
    "    class_proportions_temp = pd.Series([class_1_temp,class_2_temp,class_3_temp,class_4_temp,class_5_temp,class_6_temp])\n",
    "    \n",
    "    stdev_prop.append(np.std(class_proportions_temp))\n",
    "    \n",
    "n_classes=pd.Series(np.array(n_classes))\n",
    "stdev_prop=pd.Series(np.array(stdev_prop))\n",
    "\n",
    "variability_temp = (std_scenario_prop.iloc[0,:].max()- stdev_prop) + n_classes/12\n",
    "variability_temp = variability_temp-std_scenario_prop_norm1.iloc[0,:].min()\n",
    "variability_temp = variability_temp/std_scenario_prop_norm2.max()\n",
    "    \n",
    "variability_scarp.iloc[:,1]=variability_temp\n",
    "variability_scarp.iloc[:,0]=pred_distance['filename'][half_window_length:-half_window_length].reset_index(drop=True)\n",
    "variability_scarp.iloc[:,2]=pred_distance['distance'][half_window_length:-half_window_length].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variability_scarp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "ax.set_ylim([0,1])\n",
    "ax.plot(variability_scarp.iloc[:,0],variability_scarp.iloc[:,1])\n",
    "ax.set_title(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_variability = variability_scarp.iloc[:,1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "ax.set_ylim([0,1])\n",
    "ax.plot(scarp_length,variability_scarp.iloc[:,1])\n",
    "ax.plot(scarp_length,np.ones(len(scarp_length))*mean_variability,':',c='coral')\n",
    "ax.set_title(file_name)\n",
    "ax.set_aspect(1000)\n",
    "print(mean_variability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save variability values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"../Data2/All_variability_values/\"\n",
    "#scarp_name = \"Gildruholtsgja\"\n",
    "file = file_name+'_variability.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variability_scarp.to_csv(path+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
