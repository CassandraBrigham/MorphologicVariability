{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# morph-var 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify the profiles of a new landform using the training data and the parameters determined in morph-var 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, re\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "from scipy import interpolate as itp\n",
    "from scipy.signal import argrelextrema\n",
    "from scipy.spatial import distance\n",
    "import scipy.fftpack\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from geomdl import BSpline\n",
    "from geomdl import utilities\n",
    "from geomdl.visualization import VisMPL\n",
    "from geomdl import evaluators\n",
    "from geomdl import operations\n",
    "from geomdl import fitting\n",
    "from natsort import natsorted, index_natsorted, order_by_index\n",
    "from sklearn import preprocessing\n",
    "from scipy.stats import mode\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import math\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "import itertools\n",
    "from scipy import stats\n",
    "from sklearn import svm, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define scarp profile morphologic classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class1='VogarA_cropnorm_146.txt','VogarA_cropnorm_95.txt','VogarA_cropnorm_98.txt','VogarA_cropnorm_2.txt','Stora_Aragja_cropnorm_1.txt','Stora_Aragja_cropnorm_2.txt','Stora_Aragja_cropnorm_4.txt','Stora_Aragja_cropnorm_32.txt','Stora_Aragja_cropnorm_40.txt','Sodulholagja_cropnorm_18.txt','Sodulholagja_cropnorm_28.txt','RHPS_cropnorm_190.txt','RHPS_cropnorm_193.txt','RHPS_cropnorm_195.txt','RHPS_cropnorm_208.txt','RHPS_cropnorm_210.txt','VogarA_cropnorm_68.txt'\n",
    "class2='VogarA_cropnorm_129.txt','VogarA_cropnorm_131.txt','VogarA_cropnorm_133.txt','VogarA_cropnorm_134.txt','VogarA_cropnorm_135.txt','VogarA_cropnorm_137.txt','VogarA_cropnorm_138.txt','VogarA_cropnorm_139.txt','VogarA_cropnorm_140.txt','VogarA_cropnorm_38.txt','VogarA_cropnorm_50.txt','VogarA_cropnorm_47.txt','VogarA_cropnorm_46.txt','VogarA_cropnorm_57.txt','VogarA_cropnorm_56.txt','VogarA_cropnorm_55.txt','VogarA_cropnorm_53.txt','VogarA_cropnorm_51.txt','Stora_Aragja_cropnorm_34.txt','Stora_Aragja_cropnorm_35.txt','Stora_Aragja_cropnorm_54.txt','Stora_Aragja_cropnorm_55.txt'\n",
    "class3='LVBD-A_4_cropnorm_300.txt','LVBD-A_4_cropnorm_302.txt','LVBD-A_4_cropnorm_316.txt','LVBD-A_4_cropnorm_335.txt','LVBD-A_4_cropnorm_317.txt','LVBD-A_4_cropnorm_340.txt','LVBD-A_4_cropnorm_355.txt','LVBD-A_4_cropnorm_365.txt','LVBD-A_4_cropnorm_375.txt','LVBD-A_4_cropnorm_385.txt','LVBD-A_4_cropnorm_390.txt','LVBD-A_4_cropnorm_535.txt','LVBD-A_4_cropnorm_540.txt','LVBD-A_4_cropnorm_590.txt','LVBD-A_4_cropnorm_630.txt','LVBD-A_4_cropnorm_760.txt','LVBD-A_4_cropnorm_770.txt','VogarA_cropnorm_118.txt','VogarA_cropnorm_78.txt','Stora_Aragja_cropnorm_9.txt','Stora_Aragja_cropnorm_15.txt'\n",
    "class4='VogarA_cropnorm_30.txt','VogarA_cropnorm_33.txt','VogarA_cropnorm_35.txt','VogarA_cropnorm_41.txt','VogarA_cropnorm_61.txt','VogarA_cropnorm_63.txt','VogarA_cropnorm_64.txt','LVBD-A_1_cropnorm_136.txt','LVBD-A_1_cropnorm_145.txt','LVBD-A_1_cropnorm_147.txt','LVBD-A_1_cropnorm_155.txt','LVBD-A_1_cropnorm_275.txt','LVBD-A_1_cropnorm_276.txt','Stora_Aragja_cropnorm_41.txt','Stora_Aragja_cropnorm_60.txt','Sodulholagja_cropnorm_37.txt','Sodulholagja_cropnorm_38.txt','RHPS_cropnorm_140.txt','RHPS_cropnorm_430.txt'\n",
    "class5='LVBD-A_1_cropnorm_96.txt','LVBD-A_1_cropnorm_410.txt','LVBD-A_1_cropnorm_570.txt','LVBD-A_1_cropnorm_575.txt','LVBD-A_1_cropnorm_650.txt','LVBD-A_1_cropnorm_690.txt','LVBD-A_4_cropnorm_0.txt','LVBD-A_4_cropnorm_5.txt','LVBD-A_4_cropnorm_7.txt','LVBD-A_4_cropnorm_11.txt','LVBD-A_4_cropnorm_210.txt','LVBD-A_4_cropnorm_225.txt','LVBD-A_4_cropnorm_515.txt','Stora_Aragja_cropnorm_6.txt','Stora_Aragja_cropnorm_67.txt','RHPS_cropnorm_20.txt','RHPS_cropnorm_60.txt','RHPS_cropnorm_65.txt'\n",
    "class6='VogarA_cropnorm_26.txt','VogarA_cropnorm_28.txt','LVBD-A_1_cropnorm_100.txt','LVBD-A_1_cropnorm_101.txt','LVBD-A_1_cropnorm_102.txt','LVBD-A_1_cropnorm_104.txt','LVBD-A_1_cropnorm_106.txt','LVBD-A_1_cropnorm_114.txt','LVBD-A_1_cropnorm_117.txt','LVBD-A_1_cropnorm_130.txt','LVBD-A_1_cropnorm_164.txt','LVBD-A_1_cropnorm_166.txt','LVBD-A_1_cropnorm_167.txt','LVBD-A_1_cropnorm_450.txt','LVBD-A_1_cropnorm_800.txt','LVBD-A_1_cropnorm_854.txt','LVBD-A_4_cropnorm_150.txt','LVBD-A_4_cropnorm_155.txt','LVBD-A_4_cropnorm_151.txt','Stora_Aragja_cropnorm_44.txt','Stora_Aragja_cropnorm_51.txt','Stora_Aragja_cropnorm_58.txt','Stora_Aragja_cropnorm_59.txt','Stora_Aragja_cropnorm_64.txt','Stora_Aragja_cropnorm_68.txt','Sodulholagja_cropnorm_26.txt','RHPS_cropnorm_397.txt','RHPS_cropnorm_500.txt'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load normalized scarp profile data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_class(class_name,path):\n",
    "    #Set path to folder with training data\n",
    "    data_x_temp = []\n",
    "    data_y_temp = []\n",
    "    filenames =class_name\n",
    "    for file in filenames:\n",
    "            # Load x-coordinate data from files matching regular expression for desired class\n",
    "            data_x_temp.append(pd.read_csv(path+\"/\"+file).iloc[:,1].values)\n",
    "            # Load y-coordinate data from files matching regular expression for desired class\n",
    "            data_y_temp.append(pd.read_csv(path+\"/\"+file).iloc[:,2].values)\n",
    "            \n",
    "    # Create 4 dataframes for x,y,maxima and minima\n",
    "    dataclass_x = pd.DataFrame(data_x_temp).transpose() \n",
    "    dataclass_y = pd.DataFrame(data_y_temp).transpose()\n",
    "    dataclass_x.columns = filenames\n",
    "    dataclass_y.columns = filenames\n",
    "    \n",
    "    return dataclass_x, dataclass_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_scarp(scarp_name,path):\n",
    "    #Set path to folder with training data\n",
    "    data_x_temp = []\n",
    "    data_y_temp = []\n",
    "    filenames = [filename for filename in os.listdir(path) if re.match(scarp_name,filename)]\n",
    "    for file in filenames:\n",
    "            # Load x-coordinate data from files matching regular expression for desired class\n",
    "            data_x_temp.append(pd.read_csv(path+\"/\"+file).iloc[:,1].values)\n",
    "            # Load y-coordinate data from files matching regular expression for desired class\n",
    "            data_y_temp.append(pd.read_csv(path+\"/\"+file).iloc[:,2].values)\n",
    "            \n",
    "    # Create 4 dataframes for x,y,maxima and minima\n",
    "    dataclass_x = pd.DataFrame(data_x_temp).transpose() \n",
    "    dataclass_y = pd.DataFrame(data_y_temp).transpose()\n",
    "    dataclass_x.columns = filenames\n",
    "    dataclass_y.columns = filenames\n",
    "    \n",
    "    return dataclass_x, dataclass_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \".*.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1= \"2D_cropped_normalized/\"\n",
    "path2= 'All_cropped_normalized/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data1_x, data1_y) = load_data_class(class1,path1)\n",
    "(data2_x, data2_y) = load_data_class(class2,path1)\n",
    "(data3_x, data3_y) = load_data_class(class3,path1)\n",
    "(data4_x, data4_y) = load_data_class(class4,path1)\n",
    "(data5_x, data5_y) = load_data_class(class5,path1)\n",
    "(data6_x, data6_y) = load_data_class(class6,path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data7_x, data7_y) = load_data_scarp(file_name,path2)\n",
    "names1=data7_x.columns[data7_x.iloc[4,:].isnull()==False]\n",
    "names1=natsorted(names1)\n",
    "names2=data7_x.columns[data7_x.iloc[4,:].isnull()==True]\n",
    "names2=natsorted(names2)\n",
    "just_names=[os.path.splitext(names1[a])[0]+\"_2.txt\" for a in range(0,len(names1))]\n",
    "data7_x=data7_x[names1]\n",
    "data7_x.columns=just_names\n",
    "data7_y=data7_y[names1]\n",
    "data7_y.columns=just_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len1 = len(data1_x.columns)\n",
    "len2 = len(data2_x.columns)\n",
    "len3 = len(data3_x.columns)\n",
    "len4 = len(data4_x.columns)\n",
    "len5 = len(data5_x.columns)\n",
    "len6 = len(data6_x.columns)\n",
    "len7 = len(data7_x.columns)\n",
    "\n",
    "total_len = len1+len2+len3+len4+len5+len6+len7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = pd.concat([data1_x, data2_x, data3_x, data4_x, data5_x, data6_x, data7_x],axis=1)\n",
    "Z = pd.concat([data1_y, data2_y, data3_y, data4_y, data5_y, data6_y, data7_y],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=M.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit curve to profile data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set evaluation interval (=total number of observations in {x,y,k})\n",
    "evaluate = pd.Series(np.linspace(0,1,300))\n",
    "\n",
    "#Set the spacing at which M is evaluated\n",
    "spacing = int(len(M))\n",
    "\n",
    "x=[]\n",
    "y=[]\n",
    "\n",
    "for a in names:\n",
    "    # M and Z are the control points, convert to list of coordinate tuples L\n",
    "    if len(M[a].dropna())/spacing>5:\n",
    "        M_temp = M[a].dropna()[0::spacing]\n",
    "        Z_temp = Z[a].dropna()[0::spacing]\n",
    "    else:\n",
    "        M_temp= M[a].dropna()\n",
    "        Z_temp=Z[a].dropna()\n",
    "    L = list(zip(M_temp,Z_temp)) # zip M_temp and Z_temp to create list of tuples of points\n",
    "    # Create B-Spline curve\n",
    "    curve = BSpline.Curve() # define the BSpline curve\n",
    "    curve.degree =3# define the degree of the curve\n",
    "    curve.ctrlpts = L # set control points as list of tuples L\n",
    "    curve.knotvector = utilities.generate_knot_vector(curve.degree, len(curve.ctrlpts)) # auto-generate knot vector\n",
    "    curve.evaluate() # evaluate curve\n",
    "    # Calculate x,y coordinates and derivatives of curve at u values\n",
    "    x_temp = []\n",
    "    y_temp = []\n",
    "    for i in evaluate.iloc[:-1]:\n",
    "        ders = curve.derivatives(i, order = 2) # calculate 1st and 2nd derivatives of the curve at u, returns 3 tuples defined below.\n",
    "        x_temp2 = ders[0][0] # x-position at u\n",
    "        y_temp2 = ders[0][1] # y-position at u\n",
    "        x_temp.append(x_temp2)\n",
    "        y_temp.append(y_temp2)\n",
    "    x.append(x_temp)\n",
    "    y.append(y_temp)\n",
    "x=pd.DataFrame(x).transpose()\n",
    "x.columns=names\n",
    "y=pd.DataFrame(y).transpose()\n",
    "y.columns=names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.to_csv(\"x_all.txt\")\n",
    "y.to_csv(\"y_all.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M[a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimension reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy=[]\n",
    "for a in names:\n",
    "    xy_temp=pd.concat([x[a],y[a]],axis=1).values\n",
    "    xy_temp2=xy_temp.flatten()\n",
    "    xy.append(xy_temp2)\n",
    "xy=pd.DataFrame(xy).transpose()\n",
    "xy.columns=names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=xy\n",
    "n_features, n_samples = features.shape\n",
    "mean = pd.Series(np.mean(features, axis=1))\n",
    "features=np.zeros([n_features,n_samples])\n",
    "for a in range(0,n_samples):\n",
    "    centered_data_temp=xy.iloc[:,a]-mean\n",
    "    features[:,a]=centered_data_temp\n",
    "scaler = StandardScaler()\n",
    "features = scaler.fit_transform(features)\n",
    "\n",
    "U, S, V = scipy.linalg.svd(features,full_matrices=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_number_modes=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=proj.iloc[:len1+len2+len3+len4+len5+len6,:optimal_number_modes]\n",
    "y_train=classes\n",
    "X_test=proj.iloc[len1+len2+len3+len4+len5+len6:,:optimal_number_modes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = svm.SVC(kernel='rbf', C=5, decision_function_shape='ovo').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_predict = names[len1+len2+len3+len4+len5+len6:]\n",
    "predictions = pd.DataFrame([names_predict,y_pred]).transpose()\n",
    "predictions.columns = ['filename','class']\n",
    "predictions = predictions.reindex(index=order_by_index(predictions.index, index_natsorted(predictions['filename']))).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize classification results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to read x,y,z data from text files into three separate dataframes (dataclass_x,dataclass_y,dataclass_z) for each class. Rows of the dataframes indicate the number of points in a profile, columns indicate the index of the profiles.  \n",
    "def load_data_3(data,path):\n",
    "    #Set path to folder with training data\n",
    "    data_x_temp = []\n",
    "    data_y_temp = []\n",
    "    data_z_temp = []\n",
    "    filenames = [filename for filename in os.listdir(path) if re.match(data, filename)]\n",
    "    for file in filenames:\n",
    "            # Load x-coordinate data from files matching regular expression for desired class\n",
    "            data_x_temp.append(pd.read_csv(path+\"/\"+file).iloc[:,1].values)\n",
    "            # Load y-coordinate data from files matching regular expression for desired class\n",
    "            data_y_temp.append(pd.read_csv(path+\"/\"+file).iloc[:,2].values)\n",
    "            # Load z-coordinate data from files matching regular expression for desired class\n",
    "            data_z_temp.append(pd.read_csv(path+\"/\"+file).iloc[:,5].values) \n",
    "    # Create 3 dataframes for x,y, and z-coordinate data\n",
    "    dataclass_x = pd.DataFrame(data_x_temp).transpose() \n",
    "    dataclass_y = pd.DataFrame(data_y_temp).transpose()\n",
    "    dataclass_z = pd.DataFrame(data_z_temp).transpose()\n",
    "    dataclass_x.columns = filenames\n",
    "    dataclass_y.columns = filenames\n",
    "    dataclass_z.columns = filenames\n",
    "    return dataclass_x, dataclass_y, dataclass_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3D = scarp_name+\".*.txt\"\n",
    "path3='/Users/cassandrabrigham/Documents/RESEARCH/2021/Code/Profile extraction/Extracted_profiles/OtherHI/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data3D_x,data3D_y,data3D_z) = load_data_3(data3D,path3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names3d = pd.DataFrame(data3D_x.columns)\n",
    "names3d.columns = ['filenames']\n",
    "names3d = names3d.sort_values(by='filenames').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions3d = pd.concat([names3d,predictions['class']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_class1 = list(predictions3d['filenames'][predictions3d.index[predictions3d['class']==1]].dropna())\n",
    "pred_class2 = list(predictions3d['filenames'][predictions3d.index[predictions3d['class']==2]].dropna())\n",
    "pred_class3 = list(predictions3d['filenames'][predictions3d.index[predictions3d['class']==3]].dropna())\n",
    "pred_class4 = list(predictions3d['filenames'][predictions3d.index[predictions3d['class']==4]].dropna())\n",
    "pred_class5 = list(predictions3d['filenames'][predictions3d.index[predictions3d['class']==5]].dropna())\n",
    "pred_class6 = list(predictions3d['filenames'][predictions3d.index[predictions3d['class']==6]].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_axes_equal(ax):\n",
    "    '''Make axes of 3D plot have equal scale so that spheres appear as spheres,\n",
    "    cubes as cubes, etc..  This is one possible solution to Matplotlib's\n",
    "    ax.set_aspect('equal') and ax.axis('equal') not working for 3D.\n",
    "\n",
    "    Input\n",
    "      ax: a matplotlib axis, e.g., as output from plt.gca().\n",
    "    '''\n",
    "\n",
    "    x_limits = ax.get_xlim3d()\n",
    "    y_limits = ax.get_ylim3d()\n",
    "    z_limits = ax.get_zlim3d()\n",
    "\n",
    "    x_range = abs(x_limits[1] - x_limits[0])\n",
    "    x_middle = np.mean(x_limits)\n",
    "    y_range = abs(y_limits[1] - y_limits[0])\n",
    "    y_middle = np.mean(y_limits)\n",
    "    z_range = abs(z_limits[1] - z_limits[0])\n",
    "    z_middle = np.mean(z_limits)\n",
    "\n",
    "    # The plot bounding box is a sphere in the sense of the infinity\n",
    "    # norm, hence I call half the max range the plot radius.\n",
    "    plot_radius = 0.5*max([x_range, y_range, z_range])\n",
    "\n",
    "    ax.set_xlim3d([x_middle - plot_radius, x_middle + plot_radius])\n",
    "    ax.set_ylim3d([y_middle - plot_radius, y_middle + plot_radius])\n",
    "    ax.set_zlim3d([z_middle - plot_radius, z_middle + plot_radius])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fig = plt.figure(figsize=plt.figaspect(1)*1.5)\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "for a in pred_class1:\n",
    "    ax.plot(data3D_x[a],data3D_y[a],data3D_z[a],color='firebrick')\n",
    "for b in pred_class2:\n",
    "    ax.plot(data3D_x[b],data3D_y[b],data3D_z[b],color='darkorange')\n",
    "for c in pred_class3:\n",
    "    ax.plot(data3D_x[c],data3D_y[c],data3D_z[c],color='darkmagenta')\n",
    "for d in pred_class4:\n",
    "    ax.plot(data3D_x[d],data3D_y[d],data3D_z[d],color='orchid')\n",
    "for e in pred_class5:\n",
    "    ax.plot(data3D_x[e],data3D_y[e],data3D_z[e],color='darkcyan')\n",
    "for e in pred_class6:\n",
    "    ax.plot(data3D_x[e],data3D_y[e],data3D_z[e],color='mediumslateblue')\n",
    "set_axes_equal(ax)\n",
    "ax.elev=9000\n",
    "ax.azim=0\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_2D_class1=list(predictions['filename'][predictions.index[predictions['class']==1]].dropna())\n",
    "pred_2D_class2=list(predictions['filename'][predictions.index[predictions['class']==2]].dropna())\n",
    "pred_2D_class3=list(predictions['filename'][predictions.index[predictions['class']==3]].dropna())\n",
    "pred_2D_class4=list(predictions['filename'][predictions.index[predictions['class']==4]].dropna())\n",
    "pred_2D_class5=list(predictions['filename'][predictions.index[predictions['class']==5]].dropna())\n",
    "pred_2D_class6=list(predictions['filename'][predictions.index[predictions['class']==6]].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "ax.plot(x[pred_2D_class1],y[pred_2D_class1],color='firebrick',linewidth=0.1)\n",
    "ax.plot(x[pred_2D_class1].mean(axis=1),y[pred_2D_class1].mean(axis=1),color='firebrick',linewidth=1)\n",
    "ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "ax.plot(x[pred_2D_class2],y[pred_2D_class2],color='darkorange',linewidth=0.1)\n",
    "ax.plot(x[pred_2D_class2].mean(axis=1),y[pred_2D_class2].mean(axis=1),color='darkorange',linewidth=1)\n",
    "ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "ax.plot(x[pred_2D_class3],y[pred_2D_class3],color='darkmagenta',linewidth=0.1)\n",
    "ax.plot(x[pred_2D_class3].mean(axis=1),y[pred_2D_class3].mean(axis=1),color='darkmagenta',linewidth=1)\n",
    "ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "ax.plot(x[pred_2D_class4],y[pred_2D_class4],color='orchid',linewidth=0.1)\n",
    "ax.plot(x[pred_2D_class4].mean(axis=1),y[pred_2D_class4].mean(axis=1),color='orchid',linewidth=1)\n",
    "ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "ax.plot(x[pred_2D_class5],y[pred_2D_class5],color='darkcyan',linewidth=0.1)\n",
    "ax.plot(x[pred_2D_class5].mean(axis=1),y[pred_2D_class5].mean(axis=1),color='darkcyan',linewidth=1)\n",
    "ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "ax.plot(x[pred_2D_class6],y[pred_2D_class6],color='mediumslateblue',linewidth=0.1)\n",
    "ax.plot(x[pred_2D_class6].mean(axis=1),y[pred_2D_class6].mean(axis=1),color='mediumslateblue',linewidth=1)\n",
    "ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[pred_2D_class1].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_prof=np.array(list(range(0,len(y_pred))))*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions3d=pd.concat([predictions3d,pd.Series(dist_prof,name='distance')],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dist_1=predictions3d['distance'][predictions3d['class']==1]\n",
    "pred_dist_2=predictions3d['distance'][predictions3d['class']==2]\n",
    "pred_dist_3=predictions3d['distance'][predictions3d['class']==3]\n",
    "pred_dist_4=predictions3d['distance'][predictions3d['class']==4]\n",
    "pred_dist_5=predictions3d['distance'][predictions3d['class']==5]\n",
    "pred_dist_6=predictions3d['distance'][predictions3d['class']==6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots()\n",
    "ax.set_aspect('equal')\n",
    "ax.bar(pred_dist_1, height=25, width=2,color='firebrick')\n",
    "ax.bar(pred_dist_2, height=25, width=2,color='darkorange')\n",
    "ax.bar(pred_dist_3, height=25, width=2,color='darkmagenta')\n",
    "ax.bar(pred_dist_4, height=25, width=2,color='orchid')\n",
    "ax.bar(pred_dist_5, height=25, width=2,color='darkcyan')\n",
    "ax.bar(pred_dist_6, height=25, width=2,color='mediumslateblue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save prediction file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"../Data2/Classification_results/\"\n",
    "file = scarp_name+'_prediction.txt'\n",
    "predictions.to_csv(path+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
